{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "This notebooks has quite a few algorithms that I wrote for a Coursera Stanford Algorithms course. The algorithms are the following:\n",
    "\n",
    "- Part 1: Recursions, Divide & Conquer Algorithms\n",
    "    - Karatsuba Multiplication\n",
    "    - Merge Sort\n",
    "    - Merge Sort for 2D Matrix\n",
    "    - Strassen Subcubic Matrix Multiplication Algorithm\n",
    "- Part 2: QuickSort\n",
    "    - 4 pivots: first, last, median, random\n",
    "- Part 3: Randomized Selection\n",
    "- Part 4: Graphs And The Contraction Algorithm\n",
    "    - Min Cuts function using the contraction algorithm\n",
    "- Part 5: Graph Search and Connectivity\n",
    "    - BFS: Breath First Search\n",
    "    - BFS for shortest path\n",
    "    - DFS: Depth First Search (Recursive Version)\n",
    "    - DFS: Non recursive version\n",
    "- Part 6: Computing strongest components\n",
    "    - Kosaraju's Two Pass Algorithm\n",
    "- Part 7: Dijkstra's Shortest Path Algorithm\n",
    "    - Dijkstra's shortest path algorithm without heap\n",
    "- Part 8: Heaps\n",
    "    - Heap Implementation for min\n",
    "    - Heap Implementation for max\n",
    "    - Median maintenance\n",
    "    - Dijkstra's Shortest Path Algorithm With Heap\n",
    "- Part 9: Greedy algorithms and scheduling\n",
    "    - Scheduling with weight ratio\n",
    "\n",
    "\n",
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before changing, limit of stack = 3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "\n",
    "#code for time test:\n",
    "\"\"\"\n",
    "start = time.time()\n",
    "#total = merge_sort(other)\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "#print (elapsed)\"\"\"\n",
    "\n",
    "#use this only if you reach your recursion limit\n",
    "import sys \n",
    "# Using sys.getrecursionlimit() method \n",
    "# to find the current recursion limit\n",
    "limit = sys.getrecursionlimit()\n",
    "# Print the current limit \n",
    "print('Before changing, limit of stack =', limit) \n",
    "# New limit\n",
    "#Newlimit = 1000\n",
    "Newlimit = 3000\n",
    "# Using sys.setrecursionlimit() method \n",
    "sys.setrecursionlimit(Newlimit) \n",
    "# Using sys.getrecursionlimit() method \n",
    "# to find the current recursion limit\n",
    "limit = sys.getrecursionlimit()\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Recursions, Divide and Conquer Algorithms\n",
    "\n",
    "### Karatsuba Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3644973970887875103256527166874483211587544207895835963477629939421528736007992270278849241200677871481544064243841138279686326695257066941012572502761018079578688977798981544095519566248976723531469349839015217942200223137884660555018088304415491024358660907760939118502026290397184"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1=3141592653589793238462643383279502884197169399375105820974944592*36**50\n",
    "num2=2718281828459045235360287471352662497757247093699959574966967627*36**50\n",
    "\n",
    "def kmult(n1,n2):\n",
    "    #define when iteration stops\n",
    "    if len(str(n1))==1 or len(str(n2))==1:\n",
    "        return n1*n2\n",
    "    \n",
    "    else:\n",
    "        n=len(str(n1))//2\n",
    "        #split values\n",
    "        a, b = n1 // 10**(n), n1 % 10**(n)\n",
    "        c, d = n2 // 10**(n), n2 % 10**(n)       \n",
    "\n",
    "        #recursion function\n",
    "        ac=kmult(a,c)\n",
    "        bd=kmult(b,d)\n",
    "        rest=kmult((a+b),(c+d))\n",
    "        answer=(10**(2*n))*ac+(10**(n))*(rest-ac-bd)+bd\n",
    "        return answer\n",
    "\n",
    "kmult(num1,num2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Sort: O(nlogn)\n",
    "\n",
    "This scenario includes inversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Original List: [54044, 14108, 79294, 29649, 25260, 60660, 2995, 53777, 49689, 9083, 16122, 90436, 4615, 40660, 25675, 58943, 92904, 9900, 95588, 46120]\n",
      "Partial Ordered List: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Number of Inversions: 2407905288\n"
     ]
    }
   ],
   "source": [
    "with open('IntegerArray.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "data = [int(x.strip()) for x in data]     \n",
    "\n",
    "def merge_sort_inversions(array):\n",
    "    length = len(array)\n",
    "    answer = list()\n",
    "    counter = 0\n",
    "    \n",
    "    if length <= 1:\n",
    "        return array, 0\n",
    "    \n",
    "    #stop iteration at 1\n",
    "    else:\n",
    "        #Split the list\n",
    "        left, right = array[:(length//2)] , array[(length//2):]\n",
    "\n",
    "        #sort each half using regresion\n",
    "        L, leftcount = merge_sort_inversions(left)\n",
    "        R, rightcount = merge_sort_inversions(right)\n",
    "        \n",
    "        #function\n",
    "        i,j= 0,0\n",
    "        \n",
    "        while i< len(L) and j < len(R):\n",
    "            if L[i] < R[j]:\n",
    "                answer.append(L[i])\n",
    "                i+=1\n",
    "            else:\n",
    "                answer.append(R[j])\n",
    "                j+=1\n",
    "                counter+=len(left)-i #to add inversions all we have to include is this\n",
    "        \n",
    "        while i< len(left):\n",
    "            answer.append(L[i])\n",
    "            i+=1\n",
    "        while j < len(right):\n",
    "            answer.append(R[j])\n",
    "            j+=1\n",
    "        return answer, counter+leftcount+rightcount #we add the counter of left swaps, right swaps and between halves\n",
    "\n",
    "\n",
    "print(\"Partial Original List: \" + str(data[:20]))\n",
    "ordered_list, inversions = merge_sort_inversions(data)\n",
    "print(\"Partial Ordered List: \" + str(ordered_list[:20]))\n",
    "print(\"Number of Inversions: \" + str(inversions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Sort for 2D Matrix: nlog(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified the merge sort matrix to sort arrays in nlogn\n",
    "def merge_sort_matrix(array,index):\n",
    "    length = len(array)\n",
    "    answer = list()\n",
    "    \n",
    "    if length <= 1:\n",
    "        return array\n",
    "    \n",
    "    #stop iteration at 1\n",
    "    else:\n",
    "        #Split the list\n",
    "        left, right = array[:(length//2)] , array[(length//2):]\n",
    "\n",
    "        #sort each half using regresion\n",
    "        L = merge_sort_matrix(left,index)\n",
    "        R = merge_sort_matrix(right,index)\n",
    "        \n",
    "        #function\n",
    "        i,j= 0,0\n",
    "        \n",
    "        while i< len(L) and j < len(R):\n",
    "            if L[i][index] < R[j][index]:\n",
    "                answer.append(L[i])\n",
    "                i+=1\n",
    "            else:\n",
    "                answer.append(R[j])\n",
    "                j+=1\n",
    "        \n",
    "        while i< len(left):\n",
    "            answer.append(L[i])\n",
    "            i+=1\n",
    "        while j < len(right):\n",
    "            answer.append(R[j])\n",
    "            j+=1\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strassen Subcubic Matrix Multiplication Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 370,  396,  422,  448,  104,  104,  104,  104],\n",
       "        [ 674,  716,  758,  800,  168,  168,  168,  168],\n",
       "        [ 978, 1036, 1094, 1152,  232,  232,  232,  232],\n",
       "        [2194, 2316, 2438, 2560,  488,  488,  488,  488],\n",
       "        [ 370,  396,  422,  448,  104,  104,  104,  104],\n",
       "        [ 674,  716,  758,  800,  168,  168,  168,  168],\n",
       "        [ 978, 1036, 1094, 1152,  232,  232,  232,  232],\n",
       "        [2194, 2316, 2438, 2560,  488,  488,  488,  488]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= np.matrix('1 2 3 4 4 4 4 4; 5 6 7 8 4 4 4 4; 9 10 11 12 4 4 4 4; 25 26 27 28 4 4 4 4;1 2 3 4 4 4 4 4; 5 6 7 8 4 4 4 4; 9 10 11 12 4 4 4 4; 25 26 27 28 4 4 4 4')\n",
    "y= np.matrix('13 14 15 16 4 4 4 4; 17 18 19 20 4 4 4 4; 21 22 23 24 4 4 4 4; 25 26 27 28 4 4 4 4;1 2 3 4 4 4 4 4; 5 6 7 8 4 4 4 4; 9 10 11 12 4 4 4 4; 25 26 27 28 4 4 4 4')\n",
    "\n",
    "#Splitting the matrix in 4 blocks\n",
    "def split_matrix(matrix):\n",
    "    r, c = matrix.shape\n",
    "    a= matrix[:r//2,:r//2]\n",
    "    b= matrix[:r//2:,r//2:]\n",
    "    c= matrix[r//2:,:r//2]\n",
    "    d= matrix[r//2:,r//2:]\n",
    "    \n",
    "    return a, b, c, d\n",
    "\n",
    "def matrix_multiplication(m1,m2):\n",
    "    a, b, c, d= split_matrix(m1)\n",
    "    e, f, g, h= split_matrix(m2)\n",
    "    \n",
    "    #we only proceed with the algorithm if all blocks are the same size\n",
    "    if a.shape== b.shape== c.shape== d.shape== e.shape== f.shape== g.shape== h.shape > (1,1):\n",
    "        \n",
    "        #we call the recursion between blocks\n",
    "        ae=matrix_multiplication(a,e)\n",
    "        bg=matrix_multiplication(b,g)\n",
    "        ce=matrix_multiplication(c,e)\n",
    "        dg=matrix_multiplication(d,g)\n",
    "        af=matrix_multiplication(a,f)\n",
    "        bh=matrix_multiplication(b,h)\n",
    "        cf=matrix_multiplication(c,f)\n",
    "        dh=matrix_multiplication(d,h)\n",
    "        \n",
    "        #unite the matrix\n",
    "        col1 = np.concatenate((ae+bg,ce+dg), axis=0)\n",
    "        col2 = np.concatenate((af+bh,cf+dh), axis=0)\n",
    "        answer = np.concatenate((col1,col2), axis=1)\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        return m1*m2\n",
    "\n",
    "matrix_multiplication(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strasen Algorithm (Same recursion different formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 370,  396,  422,  448,  104,  104,  104,  104],\n",
       "        [ 674,  716,  758,  800,  168,  168,  168,  168],\n",
       "        [ 978, 1036, 1094, 1152,  232,  232,  232,  232],\n",
       "        [2194, 2316, 2438, 2560,  488,  488,  488,  488],\n",
       "        [ 370,  396,  422,  448,  104,  104,  104,  104],\n",
       "        [ 674,  716,  758,  800,  168,  168,  168,  168],\n",
       "        [ 978, 1036, 1094, 1152,  232,  232,  232,  232],\n",
       "        [2194, 2316, 2438, 2560,  488,  488,  488,  488]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= np.matrix('1 2 3 4 4 4 4 4; 5 6 7 8 4 4 4 4; 9 10 11 12 4 4 4 4; 25 26 27 28 4 4 4 4;1 2 3 4 4 4 4 4; 5 6 7 8 4 4 4 4; 9 10 11 12 4 4 4 4; 25 26 27 28 4 4 4 4')\n",
    "y= np.matrix('13 14 15 16 4 4 4 4; 17 18 19 20 4 4 4 4; 21 22 23 24 4 4 4 4; 25 26 27 28 4 4 4 4;1 2 3 4 4 4 4 4; 5 6 7 8 4 4 4 4; 9 10 11 12 4 4 4 4; 25 26 27 28 4 4 4 4')\n",
    "\n",
    "#Splitting the matrix in 4 blocks\n",
    "def split_matrix(matrix):\n",
    "    r, c = matrix.shape\n",
    "    a= matrix[:r//2,:r//2]\n",
    "    b= matrix[:r//2:,r//2:]\n",
    "    c= matrix[r//2:,:r//2]\n",
    "    d= matrix[r//2:,r//2:]\n",
    "    \n",
    "    return a, b, c, d\n",
    "\n",
    "def strauss_matrix_multiplication(x1,x2):\n",
    "    \n",
    "    a, b, c, d= split_matrix(x1)\n",
    "    e, f, g, h= split_matrix(x2)\n",
    "    \n",
    "    if a.shape== b.shape== c.shape== d.shape== e.shape== f.shape== g.shape== h.shape > (1,1):\n",
    "\n",
    "        n1=a+d\n",
    "        n2=e+h\n",
    "        n3=c+d\n",
    "        n6=f-h\n",
    "        n8=g-e\n",
    "        n9=a+b\n",
    "        n11=c-a\n",
    "        n12=e+f\n",
    "        n13=b-d\n",
    "        n14=g+h\n",
    "\n",
    "        m1=strauss_matrix_multiplication(n1,n2)\n",
    "        m2=strauss_matrix_multiplication(n3,e)\n",
    "        m3=strauss_matrix_multiplication(a,n6)\n",
    "        m4=strauss_matrix_multiplication(d,n8)\n",
    "        m5=strauss_matrix_multiplication(n9,h)\n",
    "        m6=strauss_matrix_multiplication(n11,n12)\n",
    "        m7=strauss_matrix_multiplication(n13,n14)\n",
    "\n",
    "        col1 = np.concatenate((m1+m4-m5+m7,m2+m4), axis=0)\n",
    "        col2 = np.concatenate((m3+m5,m1-m2+m3+m6), axis=0)\n",
    "        answer = np.concatenate((col1,col2), axis=1)\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        return x1*x2\n",
    "\n",
    "strauss_matrix_multiplication(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: QuickSort\n",
    "\n",
    "This algorithm is developed to be able to choose different pivots: The first number on a list, the last number, the median and a random number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quicksort1st\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "0.017839908599853516\n",
      "quicksortlast\n",
      "0.01771402359008789\n",
      "quicksortmedian\n",
      "0.01805400848388672\n",
      "quicksortrandom\n",
      "0.0184781551361084\n"
     ]
    }
   ],
   "source": [
    "count_pivot=0\n",
    "\n",
    "def partition(array):\n",
    "    r=len(array)\n",
    "    l=0\n",
    "    p=array[l]\n",
    "    i=l+1\n",
    "\n",
    "    for j in range(l+1,r):\n",
    "        #if array greater than p do nothing\n",
    "        if array[j]<p:\n",
    "            #we will swap to the left most element that is bigger than p\n",
    "            array[i], array[j] = array[j], array[i]\n",
    "            i+=1\n",
    "            \n",
    "    #we swap the p value to its final position\n",
    "    array[l], array[i-1]= array[i-1], array[l]\n",
    "    return array , i-1\n",
    "\n",
    "def choosePivot(array,kind):\n",
    "    if kind==1:\n",
    "        #for first pivot\n",
    "        pivot=array[0]\n",
    "        return array\n",
    "    elif kind==2:\n",
    "        #for last pivot\n",
    "        array[0], array[-1] = array[-1], array[0]\n",
    "        pivot = array[0]\n",
    "        return array\n",
    "    elif kind==3:\n",
    "        if len(array) % 2 == 0:\n",
    "            middle_index = len(array)//2 - 1\n",
    "        else:\n",
    "            middle_index = len(array)//2\n",
    "\n",
    "        pivot = [array[0], array[middle_index] , array[len(array)-1] ]\n",
    "        pivot.pop(pivot.index(min(pivot)))\n",
    "        pivot.pop(pivot.index(max(pivot)))\n",
    "        pivot_index= array.index(pivot[0])\n",
    "        array[0], array[pivot_index] = array[pivot_index], array[0]\n",
    "    else:\n",
    "        pivot_index= random.choice(range(len(array)))\n",
    "        array[0], array[pivot_index] = array[pivot_index], array[0]\n",
    "    return array\n",
    "            \n",
    "\n",
    "def quickSort(array,i):\n",
    "    global count_pivot\n",
    "    if len(array) >1:\n",
    "        count_pivot+=len(array)-1\n",
    "        #for first pivot, the pivot is put in the first position array[0]\n",
    "        array = choosePivot(array,i)\n",
    "        #we partition separating all te smaller values to the left of the pivot and greater to the right\n",
    "        part, index= partition(array)\n",
    "\n",
    "\n",
    "        left = quickSort(part[:index],i)\n",
    "        right = quickSort(part[(index+1):],i)\n",
    "\n",
    "        return left + [part[index]] + right\n",
    "    \n",
    "    else:\n",
    "        return array\n",
    "        \n",
    "#final homework of week 2:\n",
    "\n",
    "with open('QuickSort.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "data = [int(x.strip()) for x in data]\n",
    "\n",
    "#time test:\n",
    "start = time.time()\n",
    "total = quickSort(data,1)\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(\"quicksort1st\")\n",
    "print(total[:20])\n",
    "print (elapsed)\n",
    "start = time.time()\n",
    "total = quickSort(data,2)\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(\"quicksortlast\")\n",
    "print (elapsed)\n",
    "start = time.time()\n",
    "total = quickSort(data,3)\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(\"quicksortmedian\")\n",
    "print (elapsed)\n",
    "start = time.time()\n",
    "total = quickSort(data,4)\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(\"quicksortrandom\")\n",
    "print (elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Randomized Selection O(n)\n",
    "\n",
    "We show how randomized selection speed is supperior to quicksorts nlog(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quicksortrandom\n",
      "0.019764184951782227\n",
      "rselect\n",
      "0.0006260871887207031\n",
      "Answer:  5\n"
     ]
    }
   ],
   "source": [
    "with open('QuickSort.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "data = [int(x.strip()) for x in data]\n",
    "\n",
    "#find the ith order statistic or the ith ordered number\n",
    "def Rselect(array,order_statistic):\n",
    "    n=len(array)\n",
    "    \n",
    "    if n<=1: return array[0]\n",
    "    \n",
    "    else:\n",
    "        pivot_index= random.choice(range(n))\n",
    "        array[0], array[pivot_index] = array[pivot_index], array[0]\n",
    "        array, index=partition(array)\n",
    "\n",
    "        if index==order_statistic:\n",
    "            return array[index]\n",
    "        \n",
    "        elif index>order_statistic:\n",
    "            return Rselect(array[:index],order_statistic)\n",
    "        \n",
    "        else:\n",
    "            return Rselect(array[index+1:],order_statistic-1-index)\n",
    "        \n",
    "#comparison with quicksort\n",
    "start = time.time()\n",
    "total = quickSort(data,4)\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(\"quicksortrandom\")\n",
    "print (elapsed)\n",
    "start = time.time()\n",
    "total = Rselect(data,4)\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(\"rselect\")\n",
    "print (elapsed)\n",
    "print(\"Answer: \",total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Graphs And The Contraction Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Cuts function using the contraction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain data from file\n",
    "with open('kargerMinCut.txt', 'r') as file:\n",
    "    data_raw = file.readlines()\n",
    "\n",
    "temp=\"\"\n",
    "data_original={}\n",
    "data_line=[]\n",
    "i=0\n",
    "for y in range(len(data_raw)):\n",
    "    i+=1\n",
    "    for x in data_raw[y]:\n",
    "        if x==\"\\t\":\n",
    "            data_line.append(int(temp))\n",
    "            temp=\"\"\n",
    "        else:\n",
    "            temp+=str(x)\n",
    "    data_original[data_line[0]] = data_line[1:]\n",
    "    data_line=[]\n",
    "\n",
    "def contraction_algorithm(data):\n",
    "    #we stop when there are only 2 points\n",
    "    while len(data) > 2:\n",
    "        #we select 2 nodes (a vertex)\n",
    "        #select random node from 1 to 200\n",
    "        rn1 = random.choice(list(data))\n",
    "        #select a random node its connected to\n",
    "        rn2 = random.choice(data[rn1])\n",
    "\n",
    "        #now we will contract the vertex for this we need to delete a node, lets delete the second one\n",
    "        #remove connection from the dictionary of the first n and second n\n",
    "        data[rn1].remove(rn2)\n",
    "        data[rn2].remove(rn1)\n",
    "        #add all the new vertices to the remaining node\n",
    "        data[rn1].extend(data[rn2])\n",
    "\n",
    "        #for all other vertices connected to the second node we remove the reference to the original one\n",
    "        #and replace it by the first one\n",
    "        for element in data[rn2]:\n",
    "            data[element].remove(rn2)\n",
    "            data[element].append(rn1)\n",
    "        #we delete the second node\n",
    "        data.pop(rn2)\n",
    "\n",
    "        #we remove self references\n",
    "        while rn1 in data[rn1]: data[rn1].remove(rn1)\n",
    "\n",
    "        #we return the length of one of the two remaining points, thats the alleged min cuts\n",
    "    return len(data[list(data)[0]])\n",
    "\n",
    "def min_cuts(data2,iterations):\n",
    "    \n",
    "    answer=len(data2)*(len(data2)-1)//2\n",
    "    count=0\n",
    "    while count<iterations:\n",
    "        data=copy.deepcopy(data2) #its important to deep copy since the dictionary has lists\n",
    "        x= contraction_algorithm(data)\n",
    "        answer=min(answer,x)\n",
    "        count+=1\n",
    "        #print(answer)\n",
    "    return answer\n",
    "\n",
    "#based on the courses the probability that all iterations fail is 1/e if n^2 iterations and 1/n if nlogn\n",
    "#repeats=int(len(data_original)**2*math.log(len(data_original)))\n",
    "repeats=50\n",
    "min_cuts(data_original,repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Graph Search and Connectivity\n",
    "\n",
    "Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [4], 2: [8], 3: [6], 4: [7], 5: [2], 6: [9], 7: [1], 8: [5, 6], 9: [7, 3]}\n"
     ]
    }
   ],
   "source": [
    "#obtain the data and add them to a dictionary\n",
    "with open('SCC3.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "#remove \\n values\n",
    "data = [x.strip() for x in data]\n",
    "#use the right size\n",
    "n=int(data[-1][:data[-1].find(\" \")])\n",
    "#create empty keys for every node same for the inverse graph (modify accordingly later)\n",
    "keys = list(range(1,n+1))\n",
    "graph_ex={key: [] for key in keys}\n",
    "#create the inverse graph dictionary\n",
    "keys_inv = list(range(1,n+1))\n",
    "graph_inv_ex={key_inv: [] for key_inv in keys_inv}\n",
    "\n",
    "#add the data to its corresponding key\n",
    "for line in data:\n",
    "    position=line.find(\" \")\n",
    "    key=int(line[:position])\n",
    "    value=int(line[position+1:])\n",
    "    graph_ex[key].append(value)\n",
    "    graph_inv_ex[value].append(key)\n",
    "print(graph_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS: Breath First Search O(m+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 4, 7}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def breath_first_search(graph,start):\n",
    "    #we start with a first point added to the queue\n",
    "    Q=[start]\n",
    "    #this is the set of all the points that have been explored\n",
    "    explored= set()\n",
    "    explored.add(start)\n",
    "    #while there are values in the queue we keep going\n",
    "    while len(Q)>0:\n",
    "        #we use the first value of the queue and analize all the points it gides to\n",
    "        v=Q[0]\n",
    "        Q.pop(0) #we remove the point to analize from the queue\n",
    "        for element in graph[v]:\n",
    "            if element not in explored: #if we havent seen the next point now we have\n",
    "                explored.add(element)\n",
    "                Q.append(element) #we add that point to the queue\n",
    "    return explored\n",
    "\n",
    "#our function results in a dictionary with a value True if that point has been explored\n",
    "breath_first_search(graph_ex,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BFS for shortest path O(m+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we use bfs to compute the min distance to get to a graph\n",
    "def BFS_shortest_path(graph, start, finish):\n",
    "    #if the start and finish is the same point we are done\n",
    "    if start==finish:\n",
    "        return 0\n",
    "    else:\n",
    "        #we create the distances dictionary, it starts with false and it adds to the distance from the starting point\n",
    "        keys = graph.keys()\n",
    "        distances={key: False for key in keys}\n",
    "        distances[start]=0\n",
    "        Q=[start] #the queue consists of the first point\n",
    "\n",
    "        while len(Q)>0: #Standard BFS\n",
    "            v=Q[0]\n",
    "            Q.pop(0)\n",
    "            for element in graph[v]:\n",
    "                if distances[element]==False and element!=v: #if a point references itself its no added distance\n",
    "                    distances[element]=distances[v]+1\n",
    "                    Q.append(element)\n",
    "                \n",
    "                if element==finish: #once we find the element we care about we return the distance\n",
    "                    return distances[element]\n",
    "        return False\n",
    "\n",
    "BFS_shortest_path(graph_ex,1,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFS: Depth First Search (Recursive Version) O(m+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 4, 7}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#another way is using the same than bfs but with a stack instead of queue LILO instead of FIFO\n",
    "explored= set()\n",
    "\n",
    "def depth_first_search(graph, explored, start):\n",
    "    explored.add(start)\n",
    "    for v in graph[start]:\n",
    "        if v not in explored:\n",
    "            depth_first_search(graph, explored, v)\n",
    "\n",
    "depth_first_search(graph_ex,explored,1)\n",
    "explored            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFS: Non recursive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 4, 7}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def depth_first_search(graph,start):\n",
    "    #we start with a first point added to the stack\n",
    "    Q=[start]\n",
    "    #this is the set of all the points that have been explored\n",
    "    explored= set()\n",
    "    explored.add(start)\n",
    "    #while there are values in the stack we keep going\n",
    "    while len(Q)>0:\n",
    "        #we use the last value of the stack and analize all the points it guides to\n",
    "        v=Q[-1]\n",
    "        Q.pop(-1) #we remove the point to analize from the stack (last point)\n",
    "        for element in graph[v]:\n",
    "            if element not in explored: #if we havent seen the next point now we have\n",
    "                explored.add(element)\n",
    "                Q.append(element) #we add that point to the queue\n",
    "    return explored\n",
    "\n",
    "#our function results in a dictionary with a value True if that point has been explored\n",
    "breath_first_search(graph_ex,4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Computing strongest components\n",
    "\n",
    "### Kosaraju's Two Pass Algorithm O(m+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 6, 2: 4, 3: 4, 4: 4, 5: 6, 6: 6, 7: 9, 8: 9, 9: 9}\n",
      "[3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "#global value to iterate for first run and compute f\n",
    "t=0\n",
    "#value for second run to compute strongest components\n",
    "s=None\n",
    "\n",
    "n=len(graph_ex)\n",
    "\n",
    "def depth_first_search(graph, explored, i):\n",
    "    global t\n",
    "    global s\n",
    "    explored.add(i)\n",
    "    leader[i]=s\n",
    "    for j in graph[i]:\n",
    "        if j not in explored:\n",
    "            depth_first_search(graph, explored, j)\n",
    "    t+=1\n",
    "    f[i]=t\n",
    "\n",
    "\n",
    "\n",
    "f={key: False for key in list(range(1,n+1))}\n",
    "leader={key: False for key in list(range(1,n+1))}\n",
    "#we use this to mark the explored nodes in the first function\n",
    "explored= set()\n",
    "\n",
    "#First DFS loop with the inverse graph the result will be to fill out f completely (topological search)\n",
    "for vertex in range(n,0,-1):\n",
    "    if vertex not in explored:\n",
    "        depth_first_search(graph_inv_ex,explored,vertex)\n",
    "\n",
    "#now we want to create the final graph with the original direction but with f as node number\n",
    "final_graph={}\n",
    "#we modify the nodes with f\n",
    "for i in range(1,n+1):\n",
    "    new_list=[f[x] for x in graph_ex[i]]\n",
    "    final_graph[f[i]]=new_list\n",
    "\n",
    "#Second DFS loop with the normal graph with f for order\n",
    "explored=set()\n",
    "for vertex in range(n,0,-1):\n",
    "    if vertex not in explored:\n",
    "        s=vertex\n",
    "        depth_first_search(final_graph,explored,vertex)\n",
    "\n",
    "#problem ended\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#we finished now we get the sizes\n",
    "cluster={key: 0 for key in list(range(1,n+1))}\n",
    "for j in leader:\n",
    "    cluster[leader[j]]+=1\n",
    "end=[]\n",
    "for j in cluster:\n",
    "    if cluster[j]>0:\n",
    "        end.append(cluster[j])\n",
    "end.sort(reverse=True)\n",
    "print(leader)\n",
    "print(end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Dijkstra's Shortest Path Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain data from file\n",
    "with open('dijkstraData.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "data = [x.strip() for x in data]\n",
    "graph={}\n",
    "\n",
    "for line in data: #we go line by line adding to key\n",
    "    key_loc=line.find(\"\\t\")\n",
    "    key=int(line[:key_loc])\n",
    "    mod_line=line[key_loc+1:]\n",
    "    points=[]\n",
    "    counter=mod_line.find(\"\\t\")\n",
    "    while counter>-1: #we add each term\n",
    "        values=mod_line[:counter]\n",
    "        left=values[:values.find(\",\")]\n",
    "        right=values[values.find(\",\")+1:]\n",
    "        points.append([int(left),int(right)])\n",
    "        \n",
    "        \n",
    "        #remaining line\n",
    "        mod_line=mod_line[counter+1:]\n",
    "        counter=mod_line.find(\"\\t\")\n",
    "    \n",
    "    left=mod_line[:mod_line.find(\",\")]\n",
    "    right=mod_line[mod_line.find(\",\")+1:]\n",
    "    points.append([int(left),int(right)])\n",
    "    \n",
    "    #add to dictionary:\n",
    "    graph[key]=points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dijkstra's shortest path algorithm without heap O(m+n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03134632110595703\n",
      "{1: 0, 2: 2971, 3: 2644, 4: 3056, 5: 2525, 6: 2818, 7: 2599, 8: 1875, 9: 745, 10: 3205, 11: 1551, 12: 2906, 13: 2394, 14: 1803, 15: 2942, 16: 1837, 17: 3111, 18: 2284, 19: 1044, 20: 2351, 21: 3630, 22: 4028, 23: 2650, 24: 3653, 25: 2249, 26: 2150, 27: 1222, 28: 2090, 29: 3540, 30: 2303, 31: 3455, 32: 3004, 33: 2551, 34: 2656, 35: 998, 36: 2236, 37: 2610, 38: 3548, 39: 1851, 40: 4091, 41: 2732, 42: 2040, 43: 3312, 44: 2142, 45: 3438, 46: 2937, 47: 2979, 48: 2757, 49: 2437, 50: 3152, 51: 2503, 52: 2817, 53: 2420, 54: 3369, 55: 2862, 56: 2609, 57: 2857, 58: 3668, 59: 2947, 60: 2592, 61: 1676, 62: 2573, 63: 2498, 64: 2047, 65: 826, 66: 3393, 67: 2535, 68: 4636, 69: 3650, 70: 743, 71: 1265, 72: 1539, 73: 3007, 74: 4286, 75: 2720, 76: 3220, 77: 2298, 78: 2795, 79: 2806, 80: 982, 81: 2976, 82: 2052, 83: 3997, 84: 2656, 85: 1193, 86: 2461, 87: 1608, 88: 3046, 89: 3261, 90: 2018, 91: 2786, 92: 647, 93: 3542, 94: 3415, 95: 2186, 96: 2398, 97: 4248, 98: 3515, 99: 2367, 100: 2970, 101: 3536, 102: 2478, 103: 1826, 104: 2551, 105: 3368, 106: 2303, 107: 2540, 108: 1169, 109: 3140, 110: 2317, 111: 2535, 112: 1759, 113: 1899, 114: 508, 115: 2399, 116: 3513, 117: 2597, 118: 2176, 119: 1090, 120: 2328, 121: 2818, 122: 1306, 123: 2805, 124: 2057, 125: 2618, 126: 1694, 127: 3285, 128: 1203, 129: 676, 130: 1820, 131: 1445, 132: 2468, 133: 2029, 134: 1257, 135: 1533, 136: 2417, 137: 3599, 138: 2494, 139: 4101, 140: 546, 141: 1889, 142: 2616, 143: 2141, 144: 2359, 145: 648, 146: 2682, 147: 3464, 148: 2873, 149: 3109, 150: 2183, 151: 4159, 152: 1832, 153: 2080, 154: 1831, 155: 2001, 156: 3013, 157: 2143, 158: 1376, 159: 1627, 160: 2403, 161: 4772, 162: 2556, 163: 2124, 164: 1693, 165: 2442, 166: 3814, 167: 2630, 168: 2038, 169: 2776, 170: 1365, 171: 3929, 172: 1990, 173: 2069, 174: 3558, 175: 1432, 176: 2279, 177: 3829, 178: 2435, 179: 3691, 180: 3027, 181: 2345, 182: 3807, 183: 2145, 184: 2703, 185: 2884, 186: 3806, 187: 1151, 188: 2505, 189: 2340, 190: 2596, 191: 4123, 192: 1737, 193: 3136, 194: 1073, 195: 1707, 196: 2417, 197: 3068, 198: 1724, 199: 815, 200: 2060}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "X={1} #Traveled\n",
    "A=dict() #dictionary of distances\n",
    "A[1]=0 \n",
    "#B=dict() #dictionary of paths play and make it\n",
    "\n",
    "#check what vertices have been traveled and define a starting distance between paths\n",
    "vertices=set()\n",
    "for key in graph.keys():\n",
    "    vertices.add(key)\n",
    "    if key!=1:\n",
    "        A[key]=1000000\n",
    "\n",
    "\n",
    "v=1 #start point\n",
    "#the loop goes on until every vertex has been explored\n",
    "while X!=vertices:\n",
    "    #starting distance\n",
    "    dist=1000001\n",
    "    point=-1\n",
    "    #we iterate through every point in X to V-X\n",
    "    for xx in X:\n",
    "        #we check every path in that point\n",
    "        for w in graph[xx]:\n",
    "            #If the point doesn't belong to x we do calculations\n",
    "            if w[0] not in X:\n",
    "                #If the distance is smaller than the previous one\n",
    "                if A[xx]+w[1]<dist:\n",
    "                    #update smallest distance and point\n",
    "                    dist=A[xx]+w[1]\n",
    "                    point=w[0]\n",
    "\n",
    "    A[point]=dist\n",
    "    X.add(point)\n",
    "\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(elapsed)\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Heaps\n",
    "\n",
    "### Heap Implementation for min (logn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 5, 6, 7, 8, 7, 8, 10, 13, 9, 9]\n",
      "[1, 5, 2, 7, 8, 6, 8, 10, 13, 9, 9, 7]\n",
      "[2, 5, 6, 7, 8, 7, 8, 10, 13, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "#heapify is missing to remake the heap\n",
    "\n",
    "#for simplicity we create child and father function:\n",
    "def father(index):\n",
    "    #usually the ecuation would be parent=i//2 but bc python starts with index 0:\n",
    "    if index%2==0 and index!=0: return index//2-1\n",
    "    else: return index//2\n",
    "\n",
    "#--------\n",
    "#Implementation of insert:\n",
    "def insert(array,value):\n",
    "    #Step 1: stick k at the end of the last level\n",
    "    array.append(value)\n",
    "\n",
    "    #Step 2: if k is not the greatest number we must restore it's order\n",
    "    index=len(array)-1\n",
    "    while array[father(index)]>value:\n",
    "        array[father(index)],array[index]=array[index],array[father(index)]\n",
    "        index=father(index)\n",
    "    \n",
    "    return array\n",
    "\n",
    "#--------\n",
    "#Implementation of Extract-Min\n",
    "\n",
    "def extract_min(array):\n",
    "\n",
    "    if len(array)>3:\n",
    "        #Step 1 and 2: Delete root / move last leaf to new root\n",
    "        array[0],array[-1]=array[-1],array[0]\n",
    "        array.pop(-1)\n",
    "        \n",
    "        #Step 3: Push node down to rightful position:\n",
    "\n",
    "        index=0\n",
    "        #while the value of the index is greater than one of its branches:\n",
    "        while array[index]>=array[2*index+1] or array[index]>=array[2*index+2]:\n",
    "            #we move to the lower value of the 2 branches\n",
    "            if array[2*index+1]<=array[2*index+2]:\n",
    "                array[index],array[2*index+1]=array[2*index+1],array[index]\n",
    "                index=2*index+1\n",
    "            else:\n",
    "                array[index],array[2*index+2]=array[2*index+2],array[index]\n",
    "                index=2*index+2\n",
    "\n",
    "            #we stop the loop if it reaches the lowest possible index\n",
    "            #we do verify the case where there is only one index below and\n",
    "            #it should swap\n",
    "            if 2*index+2>len(array)-1: \n",
    "                if 2*index+1>len(array)-1:\n",
    "                    break\n",
    "                else:\n",
    "                    if array[index]>=array[2*index+1]:\n",
    "                        array[index],array[2*index+1]=array[2*index+1],array[index]\n",
    "                    break\n",
    "        \n",
    "    else:\n",
    "        array.sort()\n",
    "        array.pop(0)\n",
    "    \n",
    "    return array\n",
    "\n",
    "#Heap design for min:\n",
    "heap=[1,5,6,7,8,7,8,10,13,9,9]\n",
    "print(heap)\n",
    "heap=insert(heap,2)\n",
    "print(heap)\n",
    "heap=extract_min(heap)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heap Implementation for max (logn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 10, 8, 8, 9, 5, 7, 1, 7, 6, 9]\n",
      "[13, 10, 8, 8, 9, 5, 7, 1, 7, 6, 9, 2]\n",
      "[10, 9, 8, 8, 9, 5, 7, 1, 7, 6, 2]\n"
     ]
    }
   ],
   "source": [
    "#father function is the same for heap min and heap max\n",
    "\n",
    "#--------\n",
    "#Implementation of insert:\n",
    "def insert_max(array,value):\n",
    "    #Step 1: stick k at the end of the last level\n",
    "    array.append(value)\n",
    "\n",
    "    #Step 2: if k is not the greatest number we must restore it's order\n",
    "    index=len(array)-1\n",
    "    while array[father(index)]<value:\n",
    "        array[father(index)],array[index]=array[index],array[father(index)]\n",
    "        index=father(index)\n",
    "    \n",
    "    return array\n",
    "\n",
    "#--------\n",
    "#Implementation of Extract-Min\n",
    "\n",
    "def extract_max(array):\n",
    "\n",
    "    if len(array)>3:\n",
    "        #Step 1 and 2: Delete root / move last leaf to new root\n",
    "        array[0],array[-1]=array[-1],array[0]\n",
    "        array.pop(-1)\n",
    "        \n",
    "        #Step 3: Push node down to rightful position:\n",
    "\n",
    "        index=0\n",
    "        #while the value of the index is smaller than one of its branches:\n",
    "        while array[index]<=array[2*index+1] or array[index]<=array[2*index+2]:\n",
    "            #we move to the lower value of the 2 branches\n",
    "            if array[2*index+1]>=array[2*index+2]:\n",
    "                array[index],array[2*index+1]=array[2*index+1],array[index]\n",
    "                index=2*index+1\n",
    "            else:\n",
    "                array[index],array[2*index+2]=array[2*index+2],array[index]\n",
    "                index=2*index+2\n",
    "\n",
    "            #we stop the loop if it reaches the lowest possible index\n",
    "            #we do verify the case where there is only one index below and\n",
    "            #it should swap\n",
    "            if 2*index+2>len(array)-1: \n",
    "                if 2*index+1>len(array)-1:\n",
    "                    break\n",
    "                else:\n",
    "                    if array[index]<=array[2*index+1]:\n",
    "                        array[index],array[2*index+1]=array[2*index+1],array[index]\n",
    "                    break\n",
    "        \n",
    "    else:\n",
    "        array.sort(reverse=True)\n",
    "        array.pop(0)\n",
    "    \n",
    "    return array\n",
    "\n",
    "#Heap design for max:\n",
    "heap_pre=[1,5,6,7,8,7,8,10,13,9,9]\n",
    "heap=[]\n",
    "for x in heap_pre:\n",
    "    heap=insert_max(heap,x)\n",
    "\n",
    "print(heap)\n",
    "heap=insert_max(heap,2)\n",
    "print(heap)\n",
    "heap=extract_max(heap)\n",
    "print(heap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46831213"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtain data from file\n",
    "with open('Median.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "data=[int(x.strip()) for x in data]\n",
    "\n",
    "\n",
    "#create heap data structure with premade insert function below median on max and above median on min\n",
    "#that way the median is one of the 2 values\n",
    "\n",
    "def median_maintenance(array):\n",
    "    #we start with the first value in high:\n",
    "    hlow=[]\n",
    "    hhigh=[array[0]]\n",
    "    answer=array[0]\n",
    "\n",
    "    for x in array[1:]:\n",
    "\n",
    "        #if the new number is smaller than the min number to the right (hhigh)\n",
    "        #we add it to the left with the max heap\n",
    "        if x<=hhigh[0]:\n",
    "            hlow=insert_max(hlow,x)\n",
    "        #if not we add it to the right with the min heap\n",
    "        else:\n",
    "            hhigh=insert(hhigh,x)\n",
    "\n",
    "\n",
    "        #now we verify if we need to rebalance:\n",
    "        #first case is when hlow is greater\n",
    "        if len(hlow)==len(hhigh)+2:\n",
    "            hhigh=insert(hhigh,hlow[0]) #we add the number to extract to the right\n",
    "            hlow=extract_max(hlow) #we remove it from the left\n",
    "\n",
    "        elif len(hlow)+2==len(hhigh): #we apply the same but oposite direction\n",
    "            hlow=insert_max(hlow,hhigh[0]) #we add the number to extract to the right\n",
    "            hhigh=extract_min(hhigh) #we remove it from the left\n",
    "\n",
    "        #we add the median to the answer\n",
    "        if len(hlow)>=len(hhigh):\n",
    "            answer+=hlow[0]\n",
    "        else:\n",
    "            answer+=hhigh[0]\n",
    "            \n",
    "    return answer\n",
    "\n",
    "median_maintenance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dijkstra's Shortest Path Algorithm With Heap O(mlogn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01668405532836914\n",
      "{1: 0, 2: 2971, 3: 2644, 4: 3056, 5: 2525, 6: 2818, 7: 2599, 8: 1875, 9: 745, 10: 3205, 11: 1551, 12: 2906, 13: 2394, 14: 1803, 15: 2942, 16: 1837, 17: 3111, 18: 2284, 19: 1044, 20: 2351, 21: 3630, 22: 4028, 23: 2650, 24: 3653, 25: 2249, 26: 2150, 27: 1222, 28: 2090, 29: 3540, 30: 2303, 31: 3455, 32: 3004, 33: 2551, 34: 2656, 35: 998, 36: 2236, 37: 2610, 38: 3548, 39: 1851, 40: 4091, 41: 2732, 42: 2040, 43: 3312, 44: 2142, 45: 3438, 46: 2937, 47: 2979, 48: 2757, 49: 2437, 50: 3152, 51: 2503, 52: 2817, 53: 2420, 54: 3369, 55: 2862, 56: 2609, 57: 2857, 58: 3668, 59: 2947, 60: 2592, 61: 1676, 62: 2573, 63: 2498, 64: 2047, 65: 826, 66: 3393, 67: 2535, 68: 4636, 69: 3650, 70: 743, 71: 1265, 72: 1539, 73: 3007, 74: 4286, 75: 2720, 76: 3220, 77: 2298, 78: 2795, 79: 2806, 80: 982, 81: 2976, 82: 2052, 83: 3997, 84: 2656, 85: 1193, 86: 2461, 87: 1608, 88: 3046, 89: 3261, 90: 2018, 91: 2786, 92: 647, 93: 3542, 94: 3415, 95: 2186, 96: 2398, 97: 4248, 98: 3515, 99: 2367, 100: 2970, 101: 3536, 102: 2478, 103: 1826, 104: 2551, 105: 3368, 106: 2303, 107: 2540, 108: 1169, 109: 3140, 110: 2317, 111: 2535, 112: 1759, 113: 1899, 114: 508, 115: 2399, 116: 3513, 117: 2597, 118: 2176, 119: 1090, 120: 2328, 121: 2818, 122: 1306, 123: 2805, 124: 2057, 125: 2618, 126: 1694, 127: 3285, 128: 1203, 129: 676, 130: 1820, 131: 1445, 132: 2468, 133: 2029, 134: 1257, 135: 1533, 136: 2417, 137: 3599, 138: 2494, 139: 4101, 140: 546, 141: 1889, 142: 2616, 143: 2141, 144: 2359, 145: 648, 146: 2682, 147: 3464, 148: 2873, 149: 3109, 150: 2183, 151: 4159, 152: 1832, 153: 2080, 154: 1831, 155: 2001, 156: 3013, 157: 2143, 158: 1376, 159: 1627, 160: 2403, 161: 4772, 162: 2556, 163: 2124, 164: 1693, 165: 2442, 166: 3814, 167: 2630, 168: 2038, 169: 2776, 170: 1365, 171: 3929, 172: 1990, 173: 2069, 174: 3558, 175: 1432, 176: 2279, 177: 3829, 178: 2435, 179: 3691, 180: 3027, 181: 2345, 182: 3807, 183: 2145, 184: 2703, 185: 2884, 186: 3806, 187: 1151, 188: 2505, 189: 2340, 190: 2596, 191: 4123, 192: 1737, 193: 3136, 194: 1073, 195: 1707, 196: 2417, 197: 3068, 198: 1724, 199: 815, 200: 2060}\n"
     ]
    }
   ],
   "source": [
    "#using a heap this algorithm is more eficient\n",
    "import heapq\n",
    "start = time.time()\n",
    "X=set() #Traveled\n",
    "A=dict() #dictionary of distances\n",
    "A[1]=0 \n",
    "\n",
    "heap=list()\n",
    "#we fill the heap with it's distances and nodes\n",
    "for key in graph.keys():\n",
    "    if key!=1: A[key]=1000000\n",
    "    else: A[key]=0    \n",
    "    heap.append((A[key],key))\n",
    "\n",
    "\n",
    "while heap: #while there are terms in the heap (heap=V-X)\n",
    "    dist, w = heapq.heappop(heap) #we remove the min dist, this will be w\n",
    "    X.add(w) #we add that point as explored\n",
    "\n",
    "    for v, d in graph[w]: #we iterate every edge of node w\n",
    "        if v not in X:\n",
    "            #if v hasn't been explored, we remove it from the heap, we calculate the min distance again\n",
    "            heap.remove((A[v],v))\n",
    "            A[v]=min(A[v],A[w]+d)\n",
    "            #since we just removed a term we need to \"heapify\" the heap list again\n",
    "            heapq.heapify(heap)\n",
    "            #now that it's done we could add the term back with it's correct distance\n",
    "            heap=insert(heap,(A[v],v))\n",
    "            \n",
    "\n",
    "finish = time.time()\n",
    "elapsed = finish - start\n",
    "print(elapsed)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Greedy algorithms and scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling with weight ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67311454237\n"
     ]
    }
   ],
   "source": [
    "#obtain the data and add them to a dictionary\n",
    "with open('jobs.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "#remove \\n values\n",
    "data = [x.strip() for x in data]\n",
    "\n",
    "#we create a dictionary of every job containing it's weight and length\n",
    "jobs = dict()\n",
    "counter=1\n",
    "unexplored=set()\n",
    "for line in data[1:]:\n",
    "    unexplored.add(counter)\n",
    "    key_loc=line.find(\" \")\n",
    "    jobs[counter]= [int(line[:key_loc]) , int(line[key_loc+1:])] #[weight, length]\n",
    "    counter+=1\n",
    "\n",
    "solution=0 #counter for the solution\n",
    "length=0 #counter for the total length\n",
    "\n",
    "#we make sure every point gets explored\n",
    "while len(unexplored) > 0:\n",
    "    weight = -1000000000000000000\n",
    "    max_value = -1000000000000000000\n",
    "    diff= max_value\n",
    "    \n",
    "    for x in unexplored:\n",
    "        #we choose the value with the maximum length\n",
    "        if jobs[x][0]/jobs[x][1] > diff:\n",
    "            to_remove= x\n",
    "            weight= jobs[x][0]\n",
    "            diff= weight/jobs[x][1]\n",
    "        #if there is a tie then we choose the one with the max wieght\n",
    "        elif (jobs[x][0]/jobs[x][1] == diff) and (jobs[x][0] > weight):\n",
    "            to_remove= x\n",
    "            weight= jobs[x][0]\n",
    "    #the formula considers the sum of the length for every iteration\n",
    "    length+=jobs[to_remove][1]\n",
    "    #This is the solution formula with individual weith and total length\n",
    "    solution+=jobs[to_remove][0]*length\n",
    "    #print(\"answer\", jobs[to_remove][0], jobs[to_remove][1], length, solution)\n",
    "    #we remove the value from the list and only analize what's remaining\n",
    "    unexplored.remove(to_remove)\n",
    "\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3612829\n",
      "[144, 2, 91, 104, 223, 173, 172, 211, 428, 179, 62, 63, 267, 260, 268]\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "\n",
    "#obtain the data and add them to a dictionary\n",
    "with open('edges.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "#remove \\n values\n",
    "data = [x.strip() for x in data]\n",
    "\n",
    "#we create a dictionary of the distances of the edges with a map of it's two nodes\n",
    "graph=dict() #dictionary of distance and its edges\n",
    "V=set() #set of all the nodes to visit\n",
    "for line in data[1:]:\n",
    "    loc=line.find(\" \")\n",
    "    x1= int(line[:loc]) #coordinate x1\n",
    "    x2= line[loc+1:]\n",
    "    loc= x2.find(\" \")\n",
    "    key= int(x2[loc+1:])#cost of an edge\n",
    "    x2= int(x2[:loc]) #x2\n",
    "    #we add both points to the vertices list\n",
    "    V.add(x1)\n",
    "    V.add(x2)\n",
    "    #we add the cost to a dictionary\n",
    "    if key not in graph.keys():\n",
    "        graph[key]=[[x1, x2]]\n",
    "    else:\n",
    "        graph[key].append([x1,x2])\n",
    "\n",
    "cost=0 #this will be the cost of the minimum spanning tree\n",
    "X=set()\n",
    "T=[] #this will be the actual path followed by the tree\n",
    "X.add(3) #choose any point its the start\n",
    "while V != X:\n",
    "    min_cost=100000000000000000000000000000000\n",
    "    #we iterate through every edge\n",
    "    for edge in graph:\n",
    "        #this part is since we cant asume all costs are unique\n",
    "        for elements in graph[edge]:\n",
    "            #if one coordinate has been explored and another hasn't\n",
    "            if ((elements[0] in X) or (elements[1] in X)) \\\n",
    "            and ((elements[0] not in X) or (elements[1] not in X)):\n",
    "                #we check its cost and update if its the new min\n",
    "                if edge < min_cost:\n",
    "                    min_cost= edge\n",
    "                    x=elements[0]\n",
    "                    y=elements[1]\n",
    "    cost+=min_cost  \n",
    "    \n",
    "    #we add the newly explored point to X and add it to the path T\n",
    "    if x not in X:\n",
    "        X.add(x)\n",
    "        T.append(x)\n",
    "    else:\n",
    "        X.add(y)\n",
    "        T.append(y)\n",
    "#T is the actual path from 1\n",
    "#result is only for the homework\n",
    "print(cost)        \n",
    "print(T[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 348], [12, 373], [27, 487], [60, 175], [79, 138], [85, 333], [92, 387], [98, 112], [130, 420], [182, 225], [202, 205], [214, 361], [219, 236], [298, 420], [343, 403], [375, 454]]\n",
      "[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]\n"
     ]
    }
   ],
   "source": [
    "#we use this to recognize the cycles in the algorithm\n",
    "def dfs_cycles(graph,T,start):\n",
    "    Q=[start]\n",
    "    \n",
    "    #we have a subgraph where bfs will be made\n",
    "    sub_graph=dict()\n",
    "    sub_graph[start]=graph[start]\n",
    "    for key in T:\n",
    "        sub_graph[key]=graph[key]\n",
    "\n",
    "    explored= set()\n",
    "    explored.add(start)\n",
    "    \n",
    "    #we add this list to keep track of what has been visited\n",
    "    visited=[start]\n",
    "    \n",
    "    while len(Q)>0:\n",
    "        #we use the last value of the stack and analize all the points it guides to\n",
    "        v=Q[-1]\n",
    "        Q.pop(-1) #we remove the point to analize from the stack (last point)\n",
    "        for element in sub_graph[v]:\n",
    "            if element not in explored: #if we havent seen the next point now we have\n",
    "                visited.append(element)\n",
    "                explored.add(element)\n",
    "                Q.append(element) #we add that point to the queue\n",
    "            else:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "#our function results in a dictionary with a value True if that point has been explored\n",
    "\n",
    "#obtain the data and add them to a dictionary\n",
    "with open('clustering1.txt', 'r') as file:\n",
    "    data = file.readlines()\n",
    "#remove \\n values\n",
    "data = [x.strip() for x in data]\n",
    "#print(data[1:])\n",
    "\n",
    "order=[]\n",
    "#we create a dictionary of the distances of the edges with a map of it's two nodes\n",
    "graph_edges=dict() #dictionary of distance and its edges\n",
    "graph_nodes=dict()\n",
    "V=set() #set of all the nodes to visit\n",
    "for line in data[1:]:\n",
    "    loc=line.find(\" \")\n",
    "    x1= int(line[:loc]) #coordinate x1\n",
    "    x2= line[loc+1:]\n",
    "    loc= x2.find(\" \")\n",
    "    key= int(x2[loc+1:])#cost of an edge\n",
    "    x2= int(x2[:loc]) #x2\n",
    "    #we add both points to the vertices list\n",
    "    V.add(x1)\n",
    "    V.add(x2)\n",
    "    #we add the cost to a dictionary\n",
    "    order.append(key)\n",
    "    \n",
    "    #distance dictionary\n",
    "    if key not in graph_edges.keys():\n",
    "        graph_edges[key]=[[x1, x2]]\n",
    "    else:\n",
    "        graph_edges[key].append([x1,x2])\n",
    "    \n",
    "    #node dictionary\n",
    "    if x1 not in graph_nodes.keys():\n",
    "        graph_nodes[x1]=[x2]\n",
    "    else:\n",
    "        graph_nodes[x1].append(x2)\n",
    "\n",
    "        order.sort()\n",
    "print(graph_edges[1])\n",
    "print(graph_nodes[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
